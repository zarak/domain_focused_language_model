{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use regular expressions to remove elements that are not words such as: html tags, latex expressions, urls, digits, line returns, …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = pathlib.Path('../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = pd.read_csv(PROCESSED_DATA_DIR / 'regex_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  parent_id  comment_id  \\\n",
       "0        1        NaN         NaN   \n",
       "1        2        NaN         NaN   \n",
       "2        3        NaN         NaN   \n",
       "3        4        NaN         NaN   \n",
       "4        6        NaN         NaN   \n",
       "\n",
       "                                                text category  \n",
       "0                      Eliciting priors from experts    title  \n",
       "1                                 What is normality?    title  \n",
       "2  What are some valuable Statistical Analysis op...    title  \n",
       "3  Assessing the significance of differences in d...    title  \n",
       "4  The Two Cultures: statistics vs. machine learn...    title  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['title', 'post', 'comment'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><strong>You tend to use the covariance matrix when the variable scales are similar and the correlation matrix when variables are on different scales.</strong></p>\\n\\n<p>Using the correlation matrix is equivalent to <em>standardizing</em> each of the variables (to mean 0 and standard deviation 1). In general, PCA with and without standardizing will give different results. Especially when the scales are different.</p>\\n\\n<p>As an example, take a look at this R <code>heptathlon</code> data set. Some of the variables have an average value of about 1.8 (the high jump), whereas other variables (run 800m) are around 120.</p>\\n\\n\\n\\n\\n\\n<p>This outputs:</p>\\n\\n\\n\\n<p>Now let\\'s do PCA on covariance and on correlation:</p>\\n\\n\\n\\n<p><a href=\"https://i.stack.imgur.com/4IwjG.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/4IwjG.png\" alt=\"PCA on correlation or covariance\"></a></p>\\n\\n<p>Notice that PCA on covariance is dominated by <code>run800m</code> and <code>javelin</code>: PC1 is almost equal to <code>run800m</code> (and explains <span class=\"math-container\">$82\\\\%$</span> of the variance) and PC2 is almost equal to <code>javelin</code> (together they explain <span class=\"math-container\">$97\\\\%$</span>). <strong>PCA on correlation is much more informative</strong> and reveals some structure in the data and relationships between variables (but note that the explained variances drop to <span class=\"math-container\">$64\\\\%$</span> and <span class=\"math-container\">$71\\\\%$</span>).</p>\\n\\n<p>Notice also that the outlying individuals (in <em>this</em> data set) are outliers regardless of whether the covariance or correlation matrix is used.</p>\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = so.query(\"category == 'post'\").text.iloc[50]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><strong>You tend to use the covariance matrix when the variable scales are similar and the correlation matrix when variables are on different scales.</strong></p>\\n\\n<p>Using the correlation matrix is equivalent to <em>standardizing</em> each of the variables (to mean 0 and standard deviation 1). In general, PCA with and without standardizing will give different results. Especially when the scales are different.</p>\\n\\n<p>As an example, take a look at this R <code>heptathlon</code> data set. Some of the variables have an average value of about 1.8 (the high jump), whereas other variables (run 800m) are around 120.</p>\\n\\n\\n\\n<pre class=\"lang-r prettyprint-override\"><code>library(HSAUR)\\nheptathlon[,-8]      # look at heptathlon data (excluding \\'score\\' variable)\\n</code></pre>\\n\\n<p>This outputs:</p>\\n\\n<pre class=\"lang-r prettyprint-override\"><code>                   hurdles highjump  shot run200m longjump javelin run800m\\nJoyner-Kersee (USA)   12.69     1.86 15.80   22.56     7.27   45.66  128.51\\nJohn (GDR)            12.85     1.80 16.23   23.65     6.71   42.56  126.12\\nBehmer (GDR)          13.20     1.83 14.20   23.10     6.68   44.54  124.20\\nSablovskaite (URS)    13.61     1.80 15.23   23.92     6.25   42.78  132.24\\nChoubenkova (URS)     13.51     1.74 14.76   23.93     6.32   47.46  127.90\\n...\\n</code></pre>\\n\\n<p>Now let\\'s do PCA on covariance and on correlation:</p>\\n\\n<pre class=\"lang-r prettyprint-override\"><code># scale=T bases the PCA on the correlation matrix\\nhep.PC.cor = prcomp(heptathlon[,-8], scale=TRUE)\\nhep.PC.cov = prcomp(heptathlon[,-8], scale=FALSE)\\n\\nbiplot(hep.PC.cov)\\nbiplot(hep.PC.cor)  \\n</code></pre>\\n\\n<p><a href=\"https://i.stack.imgur.com/4IwjG.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/4IwjG.png\" alt=\"PCA on correlation or covariance\"></a></p>\\n\\n<p>Notice that PCA on covariance is dominated by <code>run800m</code> and <code>javelin</code>: PC1 is almost equal to <code>run800m</code> (and explains <span class=\"math-container\">$82\\\\%$</span> of the variance) and PC2 is almost equal to <code>javelin</code> (together they explain <span class=\"math-container\">$97\\\\%$</span>). <strong>PCA on correlation is much more informative</strong> and reveals some structure in the data and relationships between variables (but note that the explained variances drop to <span class=\"math-container\">$64\\\\%$</span> and <span class=\"math-container\">$71\\\\%$</span>).</p>\\n\\n<p>Notice also that the outlying individuals (in <em>this</em> data set) are outliers regardless of whether the covariance or correlation matrix is used.</p>\\n'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>A random variable is a variable whose value depends on unknown events.  We can summarize the unknown events as \"state\", and then the random variable is a function of the state.</p>\\n\\n<p>Example:  </p>\\n\\n<p>Suppose we have three dice rolls ($D_{1}$,$D_{2}$,$D_{3}$).  Then the state $S=(D_{1},D_{2},D_{3})$. </p>\\n\\n<ol>\\n<li>One random variable $X$ is the number of 5s. This is:</li>\\n</ol>\\n\\n<p>$$ X=(D_{1}=5?)+(D_{2}=5?)+(D_{3}=5?)$$</p>\\n\\n<ol start=\"2\">\\n<li>Another random variable $Y$ is the sum of the dice rolls. This is:</li>\\n</ol>\\n\\n<p>$$ Y=D_{1}+D_{2}+D_{3}  $$</p>\\n'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text2 = so.query(\"category == 'post'\").text.iloc[53]\n",
    "sample_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_exp = re.compile(r\"<pre[^>]*>.+?</pre>\", re.DOTALL)\n",
    "url_exp = re.compile(r\"(?P<url>(http\\S+))\")\n",
    "start_tag = re.compile(r\"<[a-z][^>]*>\")\n",
    "end_tag = re.compile(r\"</[a-z]+>\")\n",
    "latex_exp = re.compile(r\"(?P<latex>(\\$\\S+\\$))\")\n",
    "latex_exp2 = re.compile(r\"\\${2}.+\\${2}\")\n",
    "newline_exp = re.compile(r\"(?P<newline>(\\n+))\")\n",
    "digit_exp = re.compile(r\"(?P<digit>\\d+\\.*\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You tend to use the covariance matrix when the variable scales are similar and the correlation matrix when variables are on different scales. Using the correlation matrix is equivalent to standardizing each of the variables (to mean 0 and standard deviation 1). In general, PCA with and without standardizing will give different results. Especially when the scales are different. As an example, take a look at this R heptathlon data set. Some of the variables have an average value of about  (the high jump), whereas other variables (run m) are around . This outputs: Now let's do PCA on covariance and on correlation: Notice that PCA on covariance is dominated by runm and javelin: PC1 is almost equal to runm (and explains  of the variance) and PC2 is almost equal to javelin (together they explain ). PCA on correlation is much more informative and reveals some structure in the data and relationships between variables (but note that the explained variances drop to  and ). Notice also that the outlying individuals (in this data set) are outliers regardless of whether the covariance or correlation matrix is used. \""
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = code_exp.sub(\"\", sample_text)\n",
    "result = url_exp.sub(\"\", result)\n",
    "result = start_tag.sub(\"\", result)\n",
    "result = end_tag.sub(\"\", result)\n",
    "result = latex_exp.sub(\"\", result)\n",
    "result = latex_exp2.sub(\"\", result)\n",
    "result = newline_exp.sub(\" \", result)\n",
    "result = digit_exp.sub(\"\", result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "so.text.replace(code_exp, '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812127</th>\n",
       "      <td>279994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536471.0</td>\n",
       "      <td>It does run, and gives very valid looking esti...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812128</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536439.0</td>\n",
       "      <td>It seems to me that you are correct; the doubl...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812129</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536514.0</td>\n",
       "      <td>It wouldn't be the first time a grader has mis...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812130</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536802.0</td>\n",
       "      <td>The basic idea is to compare the clustering co...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812131</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>542550.0</td>\n",
       "      <td>As per your other question, your data does not...</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>812132 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id  parent_id  comment_id  \\\n",
       "0             1        NaN         NaN   \n",
       "1             2        NaN         NaN   \n",
       "2             3        NaN         NaN   \n",
       "3             4        NaN         NaN   \n",
       "4             6        NaN         NaN   \n",
       "...         ...        ...         ...   \n",
       "812127   279994        NaN    536471.0   \n",
       "812128   279998        NaN    536439.0   \n",
       "812129   279998        NaN    536514.0   \n",
       "812130   279999        NaN    536802.0   \n",
       "812131   279999        NaN    542550.0   \n",
       "\n",
       "                                                     text category  \n",
       "0                           Eliciting priors from experts    title  \n",
       "1                                      What is normality?    title  \n",
       "2       What are some valuable Statistical Analysis op...    title  \n",
       "3       Assessing the significance of differences in d...    title  \n",
       "4       The Two Cultures: statistics vs. machine learn...    title  \n",
       "...                                                   ...      ...  \n",
       "812127  It does run, and gives very valid looking esti...  comment  \n",
       "812128  It seems to me that you are correct; the doubl...  comment  \n",
       "812129  It wouldn't be the first time a grader has mis...  comment  \n",
       "812130  The basic idea is to compare the clustering co...  comment  \n",
       "812131  As per your other question, your data does not...  comment  \n",
       "\n",
       "[812132 rows x 5 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
