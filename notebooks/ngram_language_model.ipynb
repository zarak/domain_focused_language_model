{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict, Counter, namedtuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a subset of the corpus for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a training and a testing subset. Use the category “title” as the testing set and the categories “comment” and “post” as the training set. The short length of titles will make them good candidates later on as seeds for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = pathlib.Path('../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = pd.read_csv(PROCESSED_DATA_DIR / 'tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = so.loc[so.text.dropna().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = so.query(\"category != 'title'\")\n",
    "test = so.query(\"category == 'title'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set(' '.join(train.text.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the matrix of prefix - word frequencies.\n",
    "Use the ngrams function from `nltk.utils` to generate all n-grams from the corpus\n",
    "Set the following `left_pad_symbol = <s>` and `right_pad_symbol = </s>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pad_symbol = \"<s>\"\n",
    "right_pad_symbol = \"</s>\"\n",
    "\n",
    "Padding = namedtuple('Padding', ['left_pad_symbol', 'right_pad_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = Padding(\"<s>\", \"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 'e'), ('e', 's'), ('s', 't')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams('test', 2, left_pad_symbol=PADDING.left_pad_symbol, right_pad_symbol=PADDING.right_pad_symbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/yandexdataschool/nlp_course/blob/master/week03_lm/seminar.ipynb\n",
    "#\n",
    "# special tokens: \n",
    "# - unk represents absent tokens, \n",
    "# - eos is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines, n):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    :param lines: an iterable of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    When building counts, please consider the following two edge cases\n",
    "    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "      empty prefix: \"\" -> (UNK, UNK)\n",
    "      short prefix: \"the\" -> (UNK, the)\n",
    "      long prefix: \"the new approach\" -> (new, approach)\n",
    "    - you should add a special token, EOS, at the end of each sequence\n",
    "      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "      count the probability of this token just like all others.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n",
    "    for line in tqdm(lines, desc='Sentences'):\n",
    "        words = ngrams(line.split(), n,\n",
    "                            pad_left=True,\n",
    "                            pad_right=True,\n",
    "                            left_pad_symbol=PADDING.left_pad_symbol,\n",
    "                            right_pad_symbol=PADDING.right_pad_symbol)\n",
    "        for word in words:\n",
    "            prefix, target = word[:-1], word[-1]\n",
    "            counts[prefix][target] += 1\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1bc759dba8492e96cd763a84247da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sentences', max=3.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "freqs = count_ngrams(['test this planet hurrah test this planet', 'another test this planet', 'test this spoon'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs[('another', 'test')]['this']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a text generation function:  \n",
    "- takes a bigram as input and generates the next token\n",
    "- iteratively slide the prefix over the generated text so that the new prefix includes the most recent token; generates the next token\n",
    "- to generate each next token, sample the list of words associated with the prefix using the probability distribution of the prefix.\n",
    "- stop the text generation when a certain number of words have been generated or the latest token is a `</s>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(v for _, v in freqs[('test', 'this')].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = ('test', 'this')\n",
    "total_counts = sum(count for count in freqs[bigram].values())\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'this', 'spoon']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(freqs, vocab_size, delta=1.0):\n",
    "    \"\"\"Transform the counts to probabilities\"\"\"\n",
    "    for prefix in tqdm(freqs):\n",
    "        token_counts = freqs[prefix]\n",
    "        total_count = float(sum(token_counts.values()) + delta * vocab_size)\n",
    "        for w3 in freqs[prefix]:\n",
    "            token_counts[w3] = (token_counts[w3] + delta) / total_count\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(freqs, len(vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed, model, max_length=10):\n",
    "    \"\"\"Takes a bigram as input and generates the next token\"\"\"\n",
    "    assert len(seed) < max_length, \"Max length must be greater than the length of the seed\"\n",
    "    sentence_finished = False\n",
    "\n",
    "    while (not sentence_finished) and len(seed) <= max_length:\n",
    "        probs = list(model[tuple(seed[-2:])].values())\n",
    "        words = list(model[tuple(seed[-2:])].keys())\n",
    "        seed.append(np.random.choice(words, p=probs))\n",
    "        if seed[-2:] == ['</s>', '</s>']:\n",
    "            sentence_finished = True\n",
    "    return ' '.join([t for t in seed if t not in PADDING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test this planet hurrah test this spoon'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"test\", \"this\"]\n",
    "generate_text(text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that can estimate the probability of a sentence and use it to select the most probable sentence out of several candidate sentences\n",
    "- Split the sentence into trigrams and use the chain rule to calculate the probability of the sentence as a product of the bigrams - tokens probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sequence of $n$ words:\n",
    "\n",
    "$$w_1^n = w_1 \\cdots w_n$$\n",
    "\n",
    "Joint probability:\n",
    "\n",
    "$$P(w_1, w_2, \\cdots, w_n)$$\n",
    "\n",
    "Chain Rule:\n",
    "$$P(w_1^n) = \\prod_{k=1}^n P(w_k \\mid w_1^{k-1})$$\n",
    "\n",
    "Markov approximation for trigrams:\n",
    "$$P(w_n \\mid w_1^{n-1}) \\approx P(w_n \\mid w_{n-2}^{n-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(array):\n",
    "    \"\"\"Numerically stable product\"\"\"\n",
    "    return np.exp(np.sum(np.log(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unknown(model, words):\n",
    "    prefix, target = words[:-1], words[-1]\n",
    "    return model[prefix][target] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_missing_prob(model, words, vocab_set):\n",
    "    prefix, target = words[:-1], words[-1]\n",
    "    token_probs = model[prefix]\n",
    "    missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "    missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "    missing_prob_total = missing_prob_total / max(1, len(vocab_set) - len(token_probs))\n",
    "    return missing_prob_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prob(model, sentence, vocab_set):\n",
    "    words = sentence.split()\n",
    "    trigrams = ngrams(\n",
    "        words, 3, \n",
    "        left_pad_symbol=PADDING.left_pad_symbol,\n",
    "        right_pad_symbol=PADDING.right_pad_symbol\n",
    "    )\n",
    "    probs = []\n",
    "    for words in trigrams:\n",
    "        prefix, target = words[:-1], words[-1]\n",
    "        if is_unknown(model, words):\n",
    "            print(words)\n",
    "            missing_prob_total = compute_missing_prob(model, words, vocab_set)\n",
    "            probs.append(missing_prob_total)\n",
    "        else:\n",
    "            probs.append(model[prefix][target])\n",
    "    # return product(probs)\n",
    "    print(probs)\n",
    "    return np.prod(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0011636604075891564]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0011636604075891564"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_prob(model, 'the training set', vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'for': 0.0011639535165047824,\n",
       "         '?': 0.001163953516504949,\n",
       "         'omnibus': 0.001163953516504746,\n",
       "         'through': 0.001163953516504746,\n",
       "         'anyway': 0.001163953516504746,\n",
       "         'hypothesis': 0.001163953516505084,\n",
       "         'model': 0.001163953516504772,\n",
       "         'on': 0.0011639535165047772,\n",
       "         'question': 0.0011639535165047566,\n",
       "         'is': 0.0011639535165047878,\n",
       "         'with': 0.0011639535165048243,\n",
       "         'further': 0.0011639535165047514,\n",
       "         ',': 0.0011639535165048657,\n",
       "         'property': 0.001163953516504746,\n",
       "         'in': 0.0011639535165048137,\n",
       "         'by': 0.0011639535165048137,\n",
       "         'association': 0.001163953516504746,\n",
       "         '.': 0.0011639535165048865,\n",
       "         'equation': 0.001163953516504746,\n",
       "         'knowledge': 0.001163953516504746,\n",
       "         'numerically': 0.001163953516504746,\n",
       "         'effect': 0.001163953516504746,\n",
       "         'pooled': 0.001163953516504746,\n",
       "         'classifier': 0.0011639535165047514,\n",
       "         'variable': 0.001163953516504746,\n",
       "         'presupposition': 0.001163953516504746,\n",
       "         'assumption': 0.0011639535165048032,\n",
       "         'later': 0.001163953516504746,\n",
       "         'change': 0.0011639535165047514,\n",
       "         'against': 0.0011639535165047514,\n",
       "         'when': 0.0011639535165047514,\n",
       "         'one-sided': 0.001163953516504746,\n",
       "         'I': 0.0011639535165047566,\n",
       "         'as': 0.0011639535165047514,\n",
       "         'program': 0.001163953516504746,\n",
       "         'type': 0.0011639535165047514,\n",
       "         'ranking': 0.001163953516504746,\n",
       "         'approach': 0.0011639535165047566,\n",
       "         'we': 0.0011639535165047514,\n",
       "         'moderation': 0.0011639535165047514,\n",
       "         'algorithm': 0.001163953516504746,\n",
       "         'using': 0.001163953516504798,\n",
       "         'definition': 0.001163953516504746,\n",
       "         'directly': 0.0011639535165047618,\n",
       "         '</s>': 0.0011639535165047514,\n",
       "         'new': 0.001163953516504746,\n",
       "         'null': 0.0011639535165047514,\n",
       "         'out': 0.001163953516504772,\n",
       "         'marginal': 0.001163953516504746,\n",
       "         'it': 0.001163953516504746,\n",
       "         'claim': 0.0011639535165047618,\n",
       "         'within': 0.0011639535165047514,\n",
       "         'data': 0.0011639535165047514,\n",
       "         '(': 0.0011639535165047618,\n",
       "         'guess': 0.001163953516504746,\n",
       "         \"''\": 0.001163953516504746,\n",
       "         'explanation': 0.001163953516504746,\n",
       "         'instrument': 0.001163953516504746,\n",
       "         'easily': 0.001163953516504746,\n",
       "         ':': 0.0011639535165047566,\n",
       "         'than': 0.001163953516504746,\n",
       "         'empirically': 0.0011639535165047566,\n",
       "         'suspicion': 0.001163953516504746,\n",
       "         'kind': 0.001163953516504746,\n",
       "         'after': 0.0011639535165047514,\n",
       "         'you': 0.001163953516504746,\n",
       "         'either': 0.001163953516504746,\n",
       "         'F': 0.001163953516504746,\n",
       "         'comes': 0.001163953516504746,\n",
       "         'effectively': 0.001163953516504746,\n",
       "         'and': 0.0011639535165047514,\n",
       "         'more': 0.0011639535165047514,\n",
       "         'trend': 0.001163953516504746,\n",
       "         'relation': 0.001163953516504746,\n",
       "         'one': 0.001163953516504746,\n",
       "         'will': 0.0011639535165047514,\n",
       "         'confounding': 0.0011639535165047514,\n",
       "         'over': 0.001163953516504746,\n",
       "         'statistically': 0.001163953516504746,\n",
       "         'relationship': 0.001163953516504746,\n",
       "         'idea': 0.0011639535165047514,\n",
       "         'way': 0.001163953516504746,\n",
       "         'seperately': 0.001163953516504746,\n",
       "         'normal': 0.001163953516504746,\n",
       "         'number': 0.001163953516504746,\n",
       "         'condition': 0.001163953516504746,\n",
       "         'particular': 0.001163953516504746,\n",
       "         'or': 0.001163953516504746,\n",
       "         'hypotheses': 0.001163953516504746,\n",
       "         'though': 0.001163953516504746,\n",
       "         'separately': 0.001163953516504746,\n",
       "         'statistic': 0.0011639535165047514,\n",
       "         '!': 0.001163953516504746,\n",
       "         'proposed': 0.001163953516504746,\n",
       "         'post-hoc': 0.001163953516504746,\n",
       "         'since': 0.001163953516504746,\n",
       "         'tonight': 0.001163953516504746,\n",
       "         'from': 0.001163953516504746,\n",
       "         'to': 0.001163953516504746,\n",
       "         'similarly': 0.001163953516504746,\n",
       "         ';': 0.001163953516504746,\n",
       "         'beforehand': 0.001163953516504746,\n",
       "         'across': 0.001163953516504746,\n",
       "         'variant': 0.001163953516504746,\n",
       "         '$': 0.001163953516504746,\n",
       "         'because': 0.001163953516504746,\n",
       "         'sort': 0.001163953516504746,\n",
       "         'theory': 0.0011639535165047514,\n",
       "         'E.g.': 0.001163953516504746,\n",
       "         'evening': 0.001163953516504746,\n",
       "         'without': 0.001163953516504746,\n",
       "         'beyond': 0.001163953516504746,\n",
       "         '&': 0.001163953516504746,\n",
       "         'code': 0.001163953516504746,\n",
       "         'feature': 0.001163953516504746,\n",
       "         'but': 0.001163953516504746,\n",
       "         'macro': 0.001163953516504746,\n",
       "         'time': 0.001163953516504746,\n",
       "         'very': 0.001163953516504746,\n",
       "         '``': 0.001163953516504746,\n",
       "         'solution': 0.001163953516504746})"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[('test', 'this')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['test this planet', 'test this planet hurrah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test this planet'"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "max(sentences, key=lambda x: sentence_prob(model, x, vocab_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the perplexity scoring function for a given sentence and for the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, sentence, vocab_set, min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: perplexity of a sentence - scalar\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    \"\"\"\n",
    "    N = len(sentence.split())\n",
    "    value = sentence_prob(model, sentence, vocab_set)**(-1/N)\n",
    "    return max(value, min_logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(model, 'test this', vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackOverflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dc9278c6ea4697b071e64efee3aa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Sentences', max=653552.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "freqs = count_ngrams(train.text.tolist(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840998169f2f4e84a33e59efa3bd9509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3590926.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_model(freqs, len(vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"test\", \"this\"]\n",
    "generate_text(text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the perplexity of the language model on the test set composed of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4ea730fe8e43f596f5767c645a9fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=78096.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexities = test.text.progress_apply(lambda x: perplexity(model, x, vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_perplexity(perplexities, vocab_size):\n",
    "    return np.prod(perplexities)**(-1/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_perplexity(perplexities, len(vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6893"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(perplexities == np.inf).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[prefix]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
