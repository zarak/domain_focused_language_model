{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict, Counter, namedtuple\n",
    "from utils import count_ngrams, create_model, sentence_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a training and a testing subset. Use the category “title” as the testing set and the categories “comment” and “post” as the training set. The short length of titles will make them good candidates later on as seeds for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_DIR = pathlib.Path('../data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = pd.read_csv(PROCESSED_DATA_DIR / 'tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = so.loc[so.text.dropna().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = so.query(\"category != 'title'\")\n",
    "test = so.query(\"category == 'title'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = train.sample(100, random_state=0)\n",
    "small_test = test.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['test this planet hurrah test this planet', 'another test this planet', 'test this spoon']\n",
    "vocab_set = set(' '.join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vocab_set = set(' '.join(small_train.text.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the matrix of prefix - word frequencies.\n",
    "Use the ngrams function from `nltk.utils` to generate all n-grams from the corpus\n",
    "Set the following `left_pad_symbol = <s>` and `right_pad_symbol = </s>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Padding = namedtuple('Padding', ['left_pad_symbol', 'right_pad_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = Padding(\"<s>\", \"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 'e'), ('e', 's'), ('s', 't')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams('test', 2, left_pad_symbol=PADDING.left_pad_symbol, right_pad_symbol=PADDING.right_pad_symbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences: 100%|██████████| 3/3 [00:00<00:00, 194.78it/s]\n"
     ]
    }
   ],
   "source": [
    "freqs = count_ngrams(sentences, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs[('another', 'test')]['this']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('<s>', '<s>'): Counter({'test': 2, 'another': 1}),\n",
       "             ('<s>', 'test'): Counter({'this': 2}),\n",
       "             ('test', 'this'): Counter({'planet': 3, 'spoon': 1}),\n",
       "             ('this', 'planet'): Counter({'hurrah': 1, '</s>': 2}),\n",
       "             ('planet', 'hurrah'): Counter({'test': 1}),\n",
       "             ('hurrah', 'test'): Counter({'this': 1}),\n",
       "             ('planet', '</s>'): Counter({'</s>': 2}),\n",
       "             ('<s>', 'another'): Counter({'test': 1}),\n",
       "             ('another', 'test'): Counter({'this': 1}),\n",
       "             ('this', 'spoon'): Counter({'</s>': 1}),\n",
       "             ('spoon', '</s>'): Counter({'</s>': 1})})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a text generation function:  \n",
    "- takes a bigram as input and generates the next token\n",
    "- iteratively slide the prefix over the generated text so that the new prefix includes the most recent token; generates the next token\n",
    "- to generate each next token, sample the list of words associated with the prefix using the probability distribution of the prefix.\n",
    "- stop the text generation when a certain number of words have been generated or the latest token is a `</s>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(v for _, v in freqs[('test', 'this')].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = ('test', 'this')\n",
    "total_counts = sum(count for count in freqs[bigram].values())\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 4556.77it/s]\n"
     ]
    }
   ],
   "source": [
    "model = create_model(freqs, len(vocab_set), delta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed, model, max_length=10):\n",
    "    \"\"\"Takes a bigram as input and generates the next token\"\"\"\n",
    "    assert len(seed) < max_length, \"Max length must be greater than the length of the seed\"\n",
    "    sentence_finished = False\n",
    "\n",
    "    while (not sentence_finished) and len(seed) <= max_length:\n",
    "        probs = list(model[tuple(seed[-2:])].values())\n",
    "        words = list(model[tuple(seed[-2:])].keys())\n",
    "        print(probs)\n",
    "        if not words:\n",
    "            break\n",
    "        seed.append(np.random.choice(words, p=probs))\n",
    "        if seed[-2:] == ['</s>', '</s>']:\n",
    "            sentence_finished = True\n",
    "    return ' '.join([t for t in seed if t not in PADDING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('<s>', '<s>'): Counter({'test': 0.1875, 'another': 0.125}),\n",
       "             ('<s>', 'test'): Counter({'this': 0.2}),\n",
       "             ('test',\n",
       "              'this'): Counter({'planet': 0.23529411764705882,\n",
       "                      'spoon': 0.11764705882352941}),\n",
       "             ('this', 'planet'): Counter({'hurrah': 0.125, '</s>': 0.1875}),\n",
       "             ('planet', 'hurrah'): Counter({'test': 0.14285714285714285}),\n",
       "             ('hurrah', 'test'): Counter({'this': 0.14285714285714285}),\n",
       "             ('planet', '</s>'): Counter({'</s>': 0.2}),\n",
       "             ('<s>', 'another'): Counter({'test': 0.14285714285714285}),\n",
       "             ('another', 'test'): Counter({'this': 0.14285714285714285}),\n",
       "             ('this', 'spoon'): Counter({'</s>': 0.14285714285714285}),\n",
       "             ('spoon', '</s>'): Counter({'</s>': 0.14285714285714285})})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23529411764705882, 0.11764705882352941]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-d5d8c9056764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"this\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-a055810d9442>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(seed, model, max_length)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mseed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'</s>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msentence_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "text = [\"test\", \"this\"]\n",
    "generate_text(text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that can estimate the probability of a sentence and use it to select the most probable sentence out of several candidate sentences\n",
    "- Split the sentence into trigrams and use the chain rule to calculate the probability of the sentence as a product of the bigrams - tokens probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sequence of $n$ words:\n",
    "\n",
    "$$w_1^n = w_1 \\cdots w_n$$\n",
    "\n",
    "Joint probability:\n",
    "\n",
    "$$P(w_1, w_2, \\cdots, w_n)$$\n",
    "\n",
    "Chain Rule:\n",
    "$$P(w_1^n) = \\prod_{k=1}^n P(w_k \\mid w_1^{k-1})$$\n",
    "\n",
    "Markov approximation for trigrams:\n",
    "$$P(w_n \\mid w_1^{n-1}) \\approx P(w_n \\mid w_{n-2}^{n-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unknown(model, words):\n",
    "    prefix, target = words[:-1], words[-1]\n",
    "    return model[prefix][target] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_missing_prob(model, words, vocab_set):\n",
    "    prefix, target = words[:-1], words[-1]\n",
    "    token_probs = model[prefix]\n",
    "    missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "    missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "    missing_prob_total = missing_prob_total / max(1, len(vocab_set) - len(token_probs))\n",
    "    return missing_prob_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prob(model, sentence, vocab_set, min_logprob=np.log(10 ** -50.)):\n",
    "    sentence_split = sentence.split()\n",
    "    num_words = len(sentence_split)\n",
    "    trigrams = ngrams(\n",
    "        sentence_split, 3, \n",
    "        pad_left=True,\n",
    "        pad_right=True,\n",
    "        left_pad_symbol=PADDING.left_pad_symbol,\n",
    "        right_pad_symbol=PADDING.right_pad_symbol\n",
    "    )\n",
    "    probs = []\n",
    "    for words in trigrams:\n",
    "        prefix, target = words[:-1], words[-1]\n",
    "        if is_unknown(model, words):\n",
    "            missing_prob_total = compute_missing_prob(model, words, vocab_set)\n",
    "            if missing_prob_total == 0 or np.log(missing_prob_total) < min_logprob:\n",
    "                probs.append(min_logprob)\n",
    "            else:\n",
    "                probs.append(np.log(missing_prob_total))\n",
    "        else:\n",
    "            probs.append(np.log(model[prefix][target]))\n",
    "    # return product(probs)\n",
    "    return np.exp(np.sum((probs))*(-1/num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8171205928321397"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_perplexity(model, 'test this spoon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8171205928321397"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_prob(model, 'test this spoon', vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'planet': 0.75, 'spoon': 0.25})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[('test', 'this')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['test this planet', 'test this planet hurrah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test this planet'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "min(sentences, key=lambda x: sentence_prob(model, x, vocab_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the perplexity scoring function for a given sentence and for the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, sentence, vocab_set, min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: perplexity of a sentence - scalar\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    \"\"\"\n",
    "    return sentence_prob(model, sentence, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8171205928321397"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(model, 'test this spoon', vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('<s>',\n",
       "              '<s>'): Counter({'test': 0.6666666666666666,\n",
       "                      'another': 0.3333333333333333}),\n",
       "             ('<s>', 'test'): Counter({'this': 1.0}),\n",
       "             ('test', 'this'): Counter({'planet': 0.75, 'spoon': 0.25}),\n",
       "             ('this',\n",
       "              'planet'): Counter({'hurrah': 0.3333333333333333,\n",
       "                      '</s>': 0.6666666666666666}),\n",
       "             ('planet', 'hurrah'): Counter({'test': 1.0}),\n",
       "             ('hurrah', 'test'): Counter({'this': 1.0}),\n",
       "             ('planet', '</s>'): Counter({'</s>': 1.0}),\n",
       "             ('<s>', 'another'): Counter({'test': 1.0}),\n",
       "             ('another', 'test'): Counter({'this': 1.0}),\n",
       "             ('this', 'spoon'): Counter({'</s>': 1.0}),\n",
       "             ('spoon', '</s>'): Counter({'</s>': 1.0}),\n",
       "             ('hurrah', '</s>'): Counter(),\n",
       "             ('this', '</s>'): Counter(),\n",
       "             ('<s>', 'as'): Counter(),\n",
       "             ('as', 'an'): Counter(),\n",
       "             ('an', 'example'): Counter(),\n",
       "             ('example', '</s>'): Counter(),\n",
       "             ('<s>', 'this'): Counter(),\n",
       "             ('planet', 'planet'): Counter()})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackOverflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentences: 100%|██████████| 100/100 [00:00<00:00, 2724.94it/s]\n"
     ]
    }
   ],
   "source": [
    "freqs = count_ngrams(small_train.text.tolist(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5085/5085 [00:00<00:00, 538613.97it/s]\n"
     ]
    }
   ],
   "source": [
    "model = create_model(freqs, len(vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['effect', 'explanatory', '*approximation*']\n",
      "['variable']\n",
      "['in']\n",
      "['a']\n",
      "['Poisson', 'regression', 'country/state']\n",
      "['of', 'model']\n",
      "['and', 'in']\n",
      "['the']\n",
      "['structure', '``', 'exponential', 'combined', 'results', 'statistical', 'city', 'real', 'power']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'as an explanatory variable in a regression model and the structure'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"as\", \"an\"]\n",
    "generate_text(text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the perplexity of the language model on the test set composed of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zarak/anaconda3/envs/domain_focused_language_model/lib/python3.8/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad76fbe492b4920a47a720a0f3696fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexities = small_test.text.progress_apply(lambda x: perplexity(model, x, vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_perplexity(perplexities, vocab_size):\n",
    "    return np.prod(perplexities)**(-1/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7309574178771594"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_perplexity(perplexities, len(vocab_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7123372058.461836"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(model, 'as an explanatory variable in a regression model and the structure', vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
